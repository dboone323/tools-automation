name: 'MCP Auto-Fix with AI Learning'
description: 'Automatic issue resolution powered by MCP with AI learning and adaptation'
inputs:
  fix-type:
    description: 'Type of fix to apply'
    required: false
    default: 'all'
  issue_type:
    description: 'Type of issue to fix'
    required: false
  repository:
    description: 'Repository to fix'
    required: false
  error_context:
    description: 'Error context and logs'
    required: false
  workflow_id:
    description: 'Workflow run ID for learning context'
    required: false
runs:
  using: 'composite'
  steps:
    - name: Initialize AI Learning System
      shell: bash
      run: |
        echo "ðŸ§  Initializing MCP AI Learning System..."
        
        # Create learning directories
        mkdir -p .mcp_learning/{patterns,fixes,success_rates,context_db}
        
        # Initialize pattern database if not exists
        if [[ ! -f .mcp_learning/patterns/failure_patterns.json ]]; then
          cat > .mcp_learning/patterns/failure_patterns.json << 'EOF'
        {
          "version": "1.0",
          "patterns": {},
          "learning_stats": {
            "total_fixes": 0,
            "successful_fixes": 0,
            "learning_accuracy": 0.0,
            "last_updated": ""
          }
        }
        EOF
        fi
        
        echo "âœ… Learning system initialized"

    - name: Analyze Failure Pattern
      shell: bash
      run: |
        echo "ðŸ” Analyzing failure pattern..."
        
        # Create pattern analysis script
        cat > analyze_pattern.py << 'EOF'
        #!/usr/bin/env python3
        import json
        import hashlib
        import sys
        import os
        from datetime import datetime
        
        def analyze_failure_pattern(fix_type, issue_type, error_context, repository):
            # Load existing patterns
            try:
                with open('.mcp_learning/patterns/failure_patterns.json', 'r') as f:
                    patterns_db = json.load(f)
            except:
                patterns_db = {"version": "1.0", "patterns": {}, "learning_stats": {"total_fixes": 0, "successful_fixes": 0, "learning_accuracy": 0.0}}
            
            # Create pattern fingerprint
            pattern_key = f"{fix_type}:{issue_type}:{repository}"
            pattern_hash = hashlib.md5(f"{fix_type}{issue_type}{error_context}{repository}".encode()).hexdigest()[:8]
            
            # Check for similar patterns
            similar_patterns = []
            for pattern_id, pattern_data in patterns_db["patterns"].items():
                if (pattern_data.get("fix_type") == fix_type or 
                    pattern_data.get("issue_type") == issue_type):
                    similar_patterns.append({
                        "id": pattern_id,
                        "success_rate": pattern_data.get("success_rate", 0.0),
                        "fix_strategy": pattern_data.get("fix_strategy", "standard"),
                        "frequency": pattern_data.get("frequency", 1)
                    })
            
            # Sort by success rate and frequency
            similar_patterns.sort(key=lambda x: (x["success_rate"], x["frequency"]), reverse=True)
            
            # Update current pattern
            if pattern_key not in patterns_db["patterns"]:
                patterns_db["patterns"][pattern_key] = {
                    "fix_type": fix_type,
                    "issue_type": issue_type,
                    "repository": repository,
                    "first_seen": datetime.now().isoformat(),
                    "frequency": 1,
                    "success_rate": 0.0,
                    "fix_attempts": [],
                    "pattern_hash": pattern_hash,
                    "fix_strategy": "standard"
                }
            else:
                patterns_db["patterns"][pattern_key]["frequency"] += 1
            
            # Update last_updated timestamp
            patterns_db["learning_stats"]["last_updated"] = datetime.now().isoformat()
            
            # Save updated patterns
            with open('.mcp_learning/patterns/failure_patterns.json', 'w') as f:
                json.dump(patterns_db, f, indent=2)
            
            # Output analysis results
            if similar_patterns:
                best_pattern = similar_patterns[0]
                print(f"BEST_STRATEGY:{best_pattern['fix_strategy']}")
                print(f"SUCCESS_RATE:{best_pattern['success_rate']}")
                print(f"PATTERN_CONFIDENCE:{len(similar_patterns)}")
            else:
                print("BEST_STRATEGY:standard")
                print("SUCCESS_RATE:0.0")
                print("PATTERN_CONFIDENCE:0")
            
            print(f"PATTERN_KEY:{pattern_key}")
            print(f"PATTERN_HASH:{pattern_hash}")
        
        if __name__ == "__main__":
            fix_type = os.environ.get('INPUT_FIX_TYPE', 'all')
            issue_type = os.environ.get('INPUT_ISSUE_TYPE', 'unknown')
            error_context = os.environ.get('INPUT_ERROR_CONTEXT', '')
            repository = os.environ.get('INPUT_REPOSITORY', 'unknown')
            analyze_failure_pattern(fix_type, issue_type, error_context, repository)
        EOF
        
        # Run pattern analysis
        python3 analyze_pattern.py > pattern_analysis.txt
        
        # Extract analysis results
        export BEST_STRATEGY=$(grep "BEST_STRATEGY:" pattern_analysis.txt | cut -d: -f2)
        export SUCCESS_RATE=$(grep "SUCCESS_RATE:" pattern_analysis.txt | cut -d: -f2)
        export PATTERN_CONFIDENCE=$(grep "PATTERN_CONFIDENCE:" pattern_analysis.txt | cut -d: -f2)
        export PATTERN_KEY=$(grep "PATTERN_KEY:" pattern_analysis.txt | cut -d: -f2)
        export PATTERN_HASH=$(grep "PATTERN_HASH:" pattern_analysis.txt | cut -d: -f2)
        
        echo "ðŸŽ¯ Pattern Analysis Complete:"
        echo "  Strategy: $BEST_STRATEGY"
        echo "  Success Rate: $SUCCESS_RATE"
        echo "  Confidence: $PATTERN_CONFIDENCE patterns"
        
        # Save to environment for next step
        echo "BEST_STRATEGY=$BEST_STRATEGY" >> $GITHUB_ENV
        echo "SUCCESS_RATE=$SUCCESS_RATE" >> $GITHUB_ENV
        echo "PATTERN_CONFIDENCE=$PATTERN_CONFIDENCE" >> $GITHUB_ENV
        echo "PATTERN_KEY=$PATTERN_KEY" >> $GITHUB_ENV
        echo "PATTERN_HASH=$PATTERN_HASH" >> $GITHUB_ENV

    - name: Auto-Fix with AI Enhancement
      shell: bash
      run: |
        echo "ðŸ”§ Applying AI-enhanced auto-fixes..."
        
        # Record fix attempt
        FIX_START_TIME=$(date +%s)
        FIX_ID="fix_$(date +%Y%m%d_%H%M%S)_${{ inputs.fix-type }}"
        
        # Create fix attempt record
        cat > ".mcp_learning/fixes/${FIX_ID}.json" << EOF
        {
          "fix_id": "$FIX_ID",
          "fix_type": "${{ inputs.fix-type }}",
          "issue_type": "${{ inputs.issue_type }}",
          "repository": "${{ inputs.repository }}",
          "strategy": "$BEST_STRATEGY",
          "confidence": $PATTERN_CONFIDENCE,
          "success_rate": $SUCCESS_RATE,
          "start_time": "$FIX_START_TIME",
          "workflow_id": "${{ inputs.workflow_id }}",
          "pattern_key": "$PATTERN_KEY",
          "status": "in_progress"
        }
        EOF
        
        # Enhanced script creation based on learning
        FIX_SUCCESS=true
        
        # Fix missing scripts with AI enhancement
        if [ ! -f "advanced_security_scanner.sh" ]; then
          echo "ðŸ›¡ï¸ Creating AI-enhanced security scanner..."
          cat > advanced_security_scanner.sh << 'SCRIPT_EOF'
        #!/bin/bash
        # AI-Enhanced Security Scanner
        set -euo pipefail
        
        echo "ðŸ›¡ï¸ Running AI-enhanced security analysis..."
        mkdir -p security_reports
        
        # Enhanced security checks based on learning patterns
        TIMESTAMP=$(date +%Y%m%d_%H%M%S)
        REPORT_FILE="security_reports/security_${TIMESTAMP}.log"
        
        {
          echo "=== AI Security Analysis Report ==="
          echo "Timestamp: $(date)"
          echo "Repository: ${GITHUB_REPOSITORY:-$(basename $(pwd))}"
          echo ""
          
          # Check for common security patterns
          echo "ðŸ” Scanning for security patterns..."
          
          # API key exposure check
          if grep -r "api[_-]key\|API[_-]KEY" . --include="*.swift" --include="*.py" --exclude-dir=".git" 2>/dev/null; then
            echo "âš ï¸  Potential API key exposure detected"
          else
            echo "âœ… No API key exposure detected"
          fi
          
          # Hardcoded credentials check
          if grep -r "password\|secret\|token" . --include="*.swift" --include="*.py" --exclude-dir=".git" 2>/dev/null | grep -v "//"; then
            echo "âš ï¸  Potential hardcoded credentials detected"
          else
            echo "âœ… No hardcoded credentials detected"
          fi
          
          # SSL/TLS usage check
          if grep -r "http://" . --include="*.swift" --include="*.py" --exclude-dir=".git" 2>/dev/null; then
            echo "âš ï¸  Insecure HTTP usage detected"
          else
            echo "âœ… No insecure HTTP usage detected"
          fi
          
          echo ""
          echo "âœ… Security analysis complete"
          
        } > "$REPORT_FILE"
        
        echo "ðŸ“„ Security report generated: $REPORT_FILE"
        SCRIPT_EOF
          chmod +x advanced_security_scanner.sh
        fi
        
        if [ ! -f "ai_refactoring_analyzer.sh" ]; then
          echo "ðŸ§  Creating AI-enhanced refactoring analyzer..."
          cat > ai_refactoring_analyzer.sh << 'SCRIPT_EOF'
        #!/bin/bash
        # AI-Enhanced Refactoring Analyzer
        set -euo pipefail
        
        echo "ðŸ§  Running AI-enhanced refactoring analysis..."
        mkdir -p refactoring_reports
        
        TIMESTAMP=$(date +%Y%m%d_%H%M%S)
        REPORT_FILE="refactoring_reports/refactoring_${TIMESTAMP}.log"
        
        {
          echo "=== AI Refactoring Analysis Report ==="
          echo "Timestamp: $(date)"
          echo "Repository: ${GITHUB_REPOSITORY:-$(basename $(pwd))}"
          echo ""
          
          # Code complexity analysis
          echo "ðŸ” Analyzing code complexity..."
          
          # Count Swift files
          SWIFT_COUNT=$(find . -name "*.swift" -not -path "./.git/*" | wc -l | xargs)
          echo "Swift files: $SWIFT_COUNT"
          
          # Large file detection
          echo "ðŸ“ Large files (>200 lines):"
          find . -name "*.swift" -not -path "./.git/*" -exec wc -l {} \; | \
            awk '$1 > 200 {print "  " $2 " (" $1 " lines)"}' | head -10
          
          # Function complexity
          echo "ðŸ”§ Functions with high complexity:"
          find . -name "*.swift" -not -path "./.git/*" -exec grep -l "if.*{" {} \; | \
            head -5 | while read file; do
              complexity=$(grep -c "if\|for\|while\|switch" "$file" 2>/dev/null || echo "0")
              if [ "$complexity" -gt 10 ]; then
                echo "  $file (complexity: $complexity)"
              fi
            done
          
          # Duplicate code detection
          echo "ðŸ”„ Potential code duplication:"
          find . -name "*.swift" -not -path "./.git/*" -exec basename {} \; | \
            sort | uniq -d | head -5 | while read duplicate; do
              echo "  Similar filenames: $duplicate"
            done
          
          echo ""
          echo "âœ… Refactoring analysis complete"
          
        } > "$REPORT_FILE"
        
        echo "ðŸ“„ Refactoring report generated: $REPORT_FILE"
        SCRIPT_EOF
          chmod +x ai_refactoring_analyzer.sh
        fi
        
        if [ ! -f "automated_security_fixes.sh" ]; then
          echo "ðŸ”’ Creating AI-enhanced security fixes script..."
          cat > automated_security_fixes.sh << 'SCRIPT_EOF'
        #!/bin/bash
        # AI-Enhanced Automated Security Fixes
        set -euo pipefail
        
        echo "ðŸ”’ Running AI-enhanced automated security fixes..."
        mkdir -p security_reports
        
        TIMESTAMP=$(date +%Y%m%d_%H%M%S)
        FIXES_LOG="security_reports/automated_fixes_${TIMESTAMP}.log"
        
        {
          echo "=== AI Security Fixes Report ==="
          echo "Timestamp: $(date)"
          echo "Repository: ${GITHUB_REPOSITORY:-$(basename $(pwd))}"
          echo ""
          
          # Apply automatic fixes
          FIXES_APPLIED=0
          
          # Fix 1: Add .gitignore for sensitive files if missing
          if [ ! -f ".gitignore" ] || ! grep -q "*.env" .gitignore; then
            echo "ðŸ”§ Adding security patterns to .gitignore..."
            cat >> .gitignore << 'GITIGNORE_EOF'

        # Security - Environment and config files
        *.env
        *.env.local
        *.env.production
        config.plist
        secrets.json
        api_keys.txt
        
        # Build artifacts that might contain secrets
        *.dSYM/
        build/
        DerivedData/
        GITIGNORE_EOF
            echo "âœ… Enhanced .gitignore with security patterns"
            FIXES_APPLIED=$((FIXES_APPLIED + 1))
          fi
          
          # Fix 2: Check for Info.plist security settings
          if find . -name "Info.plist" | head -1 | xargs grep -q "NSAppTransportSecurity" 2>/dev/null; then
            echo "â„¹ï¸  App Transport Security configuration found"
          else
            echo "âš ï¸  Consider adding App Transport Security settings"
          fi
          
          # Fix 3: Ensure proper file permissions
          echo "ðŸ”§ Checking file permissions..."
          find . -name "*.sh" -not -path "./.git/*" -not -perm 755 -exec chmod 755 {} \; 2>/dev/null || true
          echo "âœ… Script file permissions updated"
          FIXES_APPLIED=$((FIXES_APPLIED + 1))
          
          echo ""
          echo "ðŸ“Š Summary: $FIXES_APPLIED security fixes applied"
          echo "âœ… Automated security fixes complete"
          
        } > "$FIXES_LOG"
        
        echo "ðŸ“„ Security fixes report: $FIXES_LOG"
        SCRIPT_EOF
          chmod +x automated_security_fixes.sh
        fi
        
        # Record success/failure and update learning
        FIX_END_TIME=$(date +%s)
        FIX_DURATION=$((FIX_END_TIME - FIX_START_TIME))
        
        # Update fix record and learning database
        python3 << EOF
        import json
        from datetime import datetime
        import os
        
        # Update fix record
        fix_id = "$FIX_ID"
        try:
            with open(f'.mcp_learning/fixes/{fix_id}.json', 'r') as f:
                fix_record = json.load(f)
            
            fix_record.update({
                "end_time": "$FIX_END_TIME",
                "duration_seconds": $FIX_DURATION,
                "success": $FIX_SUCCESS,
                "status": "completed"
            })
            
            with open(f'.mcp_learning/fixes/{fix_id}.json', 'w') as f:
                json.dump(fix_record, f, indent=2)
        except Exception as e:
            print(f"Warning: Could not update fix record: {e}")
        
        # Update pattern success rates
        try:
            with open('.mcp_learning/patterns/failure_patterns.json', 'r') as f:
                patterns_db = json.load(f)
            
            pattern_key = "$PATTERN_KEY"
            if pattern_key in patterns_db["patterns"]:
                pattern = patterns_db["patterns"][pattern_key]
                pattern["fix_attempts"].append({
                    "fix_id": fix_id,
                    "success": $FIX_SUCCESS,
                    "timestamp": datetime.now().isoformat()
                })
                
                # Recalculate success rate
                successes = sum(1 for attempt in pattern["fix_attempts"] if attempt["success"])
                total_attempts = len(pattern["fix_attempts"])
                pattern["success_rate"] = successes / total_attempts if total_attempts > 0 else 0.0
                
                # Update strategy based on success rate
                if pattern["success_rate"] >= 0.8:
                    pattern["fix_strategy"] = "proven"
                elif pattern["success_rate"] >= 0.6:
                    pattern["fix_strategy"] = "reliable"
                elif pattern["success_rate"] >= 0.4:
                    pattern["fix_strategy"] = "experimental"
                else:
                    pattern["fix_strategy"] = "needs_review"
            
            # Update global stats
            patterns_db["learning_stats"]["total_fixes"] += 1
            if $FIX_SUCCESS:
                patterns_db["learning_stats"]["successful_fixes"] += 1
            
            total = patterns_db["learning_stats"]["total_fixes"]
            successful = patterns_db["learning_stats"]["successful_fixes"]
            patterns_db["learning_stats"]["learning_accuracy"] = successful / total if total > 0 else 0.0
            patterns_db["learning_stats"]["last_updated"] = datetime.now().isoformat()
            
            with open('.mcp_learning/patterns/failure_patterns.json', 'w') as f:
                json.dump(patterns_db, f, indent=2)
            
            print(f"ðŸ§  Learning updated: {successful}/{total} success rate ({successful/total:.1%})")
        except Exception as e:
            print(f"Warning: Could not update learning database: {e}")
        EOF
        
        echo "âœ… AI-enhanced auto-fix completed"

    - name: Learning Summary Report
      if: always()
      shell: bash
      run: |
        echo "ðŸ§  MCP AI Learning Summary"
        echo "========================="
        
        # Display learning stats
        python3 << 'EOF'
        import json
        
        try:
            with open('.mcp_learning/patterns/failure_patterns.json', 'r') as f:
                patterns_db = json.load(f)
            
            stats = patterns_db["learning_stats"]
            print(f"ðŸ“Š Total Fixes Attempted: {stats['total_fixes']}")
            print(f"âœ… Successful Fixes: {stats['successful_fixes']}")
            print(f"ðŸŽ¯ Learning Accuracy: {stats['learning_accuracy']:.1%}")
            print(f"ðŸ“š Patterns Learned: {len(patterns_db['patterns'])}")
            print(f"ðŸ• Last Updated: {stats.get('last_updated', 'Never')}")
            
            # Show top performing patterns
            patterns = [(k, v) for k, v in patterns_db["patterns"].items()]
            patterns.sort(key=lambda x: (x[1].get("success_rate", 0), x[1].get("frequency", 0)), reverse=True)
            
            if patterns:
                print("\nðŸ† Top Performing Patterns:")
                for i, (pattern_key, pattern_data) in enumerate(patterns[:3], 1):
                    success_rate = pattern_data.get("success_rate", 0) * 100
                    frequency = pattern_data.get("frequency", 0)
                    strategy = pattern_data.get("fix_strategy", "unknown")
                    print(f"  {i}. {pattern_key}")
                    print(f"     Success: {success_rate:.1f}% | Frequency: {frequency} | Strategy: {strategy}")
            
            # Show recent learning trends
            print(f"\nðŸ”® Learning System Status: {'Active' if stats['total_fixes'] > 0 else 'Initializing'}")
            if stats['total_fixes'] > 0:
                print(f"   The AI system has learned from {stats['total_fixes']} fix attempts")
                print(f"   Current success rate trending at {stats['learning_accuracy']:.1%}")
        
        except Exception as e:
            print(f"Learning stats unavailable: {e}")
            print("ðŸš€ Learning system is initializing...")
        EOF
        
        echo ""
        echo "ðŸ”® AI learning system continues to evolve with each fix attempt"
        echo "   Future fixes will be more accurate based on accumulated knowledge"
